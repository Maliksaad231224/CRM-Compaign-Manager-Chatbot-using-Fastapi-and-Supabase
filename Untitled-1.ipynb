{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af943306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d91c1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2c701dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"term_deposit_campaigns\"\n",
    "\n",
    "rows = supabase.table(table_name).select(\"*\").execute().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78aeefc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1aa6528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 384)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "embeddings = []\n",
    "row_data = []\n",
    "\n",
    "for row in rows:\n",
    "    emb_str = row.get(\"embedding_vector\")  # your column name\n",
    "    if emb_str:\n",
    "        # Convert string to list\n",
    "        emb_list = ast.literal_eval(emb_str)\n",
    "        embeddings.append(np.array(emb_list, dtype=np.float32))\n",
    "        row_data.append(row)\n",
    "\n",
    "# Now stack into a matrix\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44731022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b)\n",
    "    return np.dot(a_norm, b_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb923dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query, top_k=10):\n",
    "    query_emb = model.encode(query)\n",
    "    sims = cosine_similarity(embeddings, query_emb)  # shape: (num_rows,)\n",
    "    top_idx = np.argsort(sims)[-top_k:][::-1]  # indices of top-k similar rows\n",
    "    results = [row_data[i] for i in top_idx]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c56c6c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the retrieved data, the customers with the highest balances (top 10) are:\n",
      "\n",
      "1. **ID: 342** – Balance: **693**\n",
      "2. **ID: 557** – Balance: **471**\n",
      "3. **ID: 279** – Balance: **570**\n",
      "4. **ID: 179** – Balance: **214**\n",
      "5. **ID: 455** – Balance: **270**\n",
      "6. **ID: 796** – Balance: **144**\n",
      "7. **ID: 998** – Balance: **61**\n",
      "8. **ID: 832** – Balance: **19**\n",
      "9. **ID: 28** – Balance: **113**\n",
      "10. **ID: 895** – Balance: **56**\n",
      "\n",
      "*(Sorted in descending order of balance.)*\n"
     ]
    }
   ],
   "source": [
    "import openai \n",
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.llm7.io/v1\",\n",
    "    api_key=\"unused\"  # Or get it for free at https://token.llm7.io/ for higher rate limits.\n",
    ")\n",
    "\n",
    "query = \"Find customers with high balance. I want top 10\"\n",
    "top_rows = query_rag(query, top_k=10)\n",
    "\n",
    "context = \"\\n\".join([str(r) for r in top_rows])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an AI assistant. You must answer ONLY using the information provided in the \"Retrieved Data\" section.\n",
    "Do NOT use outside knowledge. Do NOT guess. Do NOT fill in missing details.\n",
    "\n",
    "### Retrieved Data:\n",
    "{context}\n",
    "\n",
    "### User Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model='default',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
